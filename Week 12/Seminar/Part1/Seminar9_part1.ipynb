{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cccb3519",
   "metadata": {
    "id": "cccb3519"
   },
   "source": [
    "###  Градиентный бустинг.\n",
    "\n",
    "#### Catboost vs. LightGBM vs. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ce0426",
   "metadata": {
    "id": "40ce0426"
   },
   "source": [
    "В прошлый раз мы посмотрели простую версию градиентного бустинга из scikit-learn, [придуманную в 1999 году Фридманом](https://projecteuclid.org/download/pdf_1/euclid.aos/1013203451). Прогресс не стоит на месте, и на сегодняшний день есть три популярные библиотеки с разными имплементациями градиентного бустинга, которые на практике показывают лушие результаты:\n",
    "*  **XGBoost**. Появилась в 2014 году, [статья автора](https://arxiv.org/pdf/1603.02754.pdf) вышла в 2016. После выхода быстро набрала популярность и оставалась стандартом до конца 2016 года. Об особенностях данной библиотеки рассказывалось на лекции.\n",
    "* **CatBoost** от компании Яндекс с релизом в 2017 году. Алгоритм можно запускать с дефолтными гиперпараметрами, потому тчо он является менее чувствительным к выбору их конкретных значений. Отлично умеет работать с категориальным признаками, при этом автоматически обрабатывая полученные на вход непредобработанные фичи.\n",
    "* **LightGBM**. Релиз в один год с Catboost, библиотека от Microsoft. Отличается очень быстрым построением композиции. Например, при построении узла дерева, вместо перебора по всем значениям признака, производится перебор значений гистограммы этого признака. Таким образом, вместо $O(N)$ требуется $O$(m), где $m$ - число бинов гистограммы. В отличие от других библиотек, строит деревья в глубину, при этом на каждом шаге строит вершину, дающую наибольшее уменьшение функционала."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3129ca",
   "metadata": {
    "id": "1e3129ca"
   },
   "source": [
    "\n",
    "\n",
    "|Критерий|Catboost|Lightgbm|Xgboost|\n",
    "|--|--|--|--|\n",
    "|Год релиза|2014|2017|2017|\n",
    "|Построение деревьев|симметрично по уровням|в глубину|асимметрично по уровням до максимальной глубины с прунингом|\n",
    "|Параметры контроля переобучения|learning_rate, depth, l2-leaf-reg (аналога min_child_weigth нет) |learning_rate, max_depth, num_leaves, min_data_in_leaf|learning_rate (eta), min_child_weigth, max_depth|\n",
    "|Контроль скорости обучения|rsm, iterations|feature_fraction, bagging_fraction, num_iterations|n_estimator, colsample_bytree, subsample|\n",
    "|Параметры категориальных фичей|cat_features, one_hot_max_size|categorical_feature|не доступно|\n",
    "|Бинаризация признаков|сетка выбирается заранее|-|перебор всех границ, выбор сетки на каждой итерации|\n",
    "|Скор сплита|Похожесть векторов градиентов |-| Смотрим на изменение функции ошибки|\n",
    "|Bootstrap|Можно перевзвешивать и менять интенсивность |-|-|\n",
    "|Рандомизация скора сплита|+ |-|-|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f364f9",
   "metadata": {
    "id": "e3f364f9"
   },
   "source": [
    "### Основные параметры\n",
    "\n",
    "* objective – функция ошибки для настройки композиция\n",
    "* learning_rate / eta – скорость обучения\n",
    "* n_estimators / num_iterations – число итераций градиентного бустинга\n",
    "\n",
    "### Настройка сложности деревьев\n",
    "\n",
    "* max_depth – максимальная глубина\n",
    "* max_leaves / num_leaves – максимальное число вершин в дереве\n",
    "* gamma / min_gain_to_split – порог на уменьшение функции ошибки при расщеплении в дереве\n",
    "* min_data_in_leaf – минимальное число объектов в листе\n",
    "* min_sum_hessian_in_leaf – минимальная сумма весов объектов в листе, минимальное число объектов, при котором делается расщепление\n",
    "* lambda – коэффициент регуляризации (L2)\n",
    "* subsample / bagging_fraction – какую часть объектов обучения использовать для построения одного дерева\n",
    "* colsample_bytree / feature_fraction – какую часть признаков использовать для построения одного дерева\n",
    "\n",
    "Начать настройку можно с самых главных параметров: learning_rate и n_estimators. Один из них фиксируем, оставшийся из этих двух параметров подбираем (например, подбираем скорость обучения при n_estimators=100). Следующий параметр по важности - max_depth, так как мы хотим неглубокие деревья (в Catboost и LightGBM) для снижения переобучения.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236227fc",
   "metadata": {
    "id": "236227fc"
   },
   "source": [
    "**Техническое отступление**\n",
    "\n",
    "Данные библиотеки необходимо сначала устанавливать (можно через pip / conda или brew, если Вы работаете на MAC OS).\n",
    "Чтобы у Вас точно вопроизводился ноутбук и не было проблем из-за несовпадающих версий библиотек, рекомендуется через python создавать виртуальную среду. Подробнее см. файлики ```техническое_отступление.md``` и ```requirements.txt```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7937f74b",
   "metadata": {
    "id": "7937f74b"
   },
   "source": [
    "В текущем ноутбуке использовались следующие версии библиотек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0bdbfd",
   "metadata": {
    "id": "7b0bdbfd"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "python3.8 -m venv my_venv\n",
    "source my_venv/bin/activate\n",
    "pip install -r requirements.txt\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bb04ac",
   "metadata": {
    "id": "b3bb04ac"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "!pip install catboost==1.0.3\n",
    "!pip install lightgbm==3.2.1\n",
    "!pip install cmake==3.22.0 # без нее xgboost установится, но не будет импортироваться\n",
    "!pip install xgboost==1.5.0\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mYTUV4_lCrN3",
   "metadata": {
    "id": "mYTUV4_lCrN3"
   },
   "outputs": [],
   "source": [
    "#!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc1bb59",
   "metadata": {
    "id": "3bc1bb59"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import catboost\n",
    "import lightgbm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1becb5a1",
   "metadata": {
    "id": "1becb5a1"
   },
   "source": [
    "### Catboost\n",
    "\n",
    "В алгоритме сделаны улучшения и выбор разных опций для борьбы с переобучением, подсчету сркднего таргета на отложенной выборке, подсчету статистик по категориальным фичам, бинаризацией фичей, рандомизации скора сплита, разные типы бутсрапирования.\n",
    "\n",
    "Давайте сначала зафиксируем все гиперпараметры со значениями по умолчанию, кроме количества деревьев в композиции - `n_estimators`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16301cf",
   "metadata": {
    "id": "b16301cf"
   },
   "outputs": [],
   "source": [
    "def plot_surface(X, y, clf):\n",
    "    h = 0.2\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "    # Добавим на график сами наблюдения\n",
    "    cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "\n",
    "X, y = make_classification(n_samples=500, n_features=2, n_informative=2,\n",
    "                           n_redundant=0, n_repeated=0,\n",
    "                           n_classes=2, n_clusters_per_class=2,\n",
    "                           flip_y=0.05, class_sep=0.8, random_state=241)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ed77c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "executionInfo": {
     "elapsed": 1174,
     "status": "ok",
     "timestamp": 1700475862938,
     "user": {
      "displayName": "Sergey Korpachev",
      "userId": "09181340988160569540"
     },
     "user_tz": -180
    },
    "id": "60ed77c9",
    "outputId": "c50278a5-c6c5-4c22-bc0d-5ba38b810262"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "catboost = CatBoostClassifier(n_estimators=300, logging_level='Silent')\n",
    "catboost.fit(X_train, y_train)\n",
    "plot_surface(X_test, y_test, catboost)\n",
    "\n",
    "print(roc_auc_score(y_test, catboost.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c79232a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "executionInfo": {
     "elapsed": 10172,
     "status": "ok",
     "timestamp": 1700475873106,
     "user": {
      "displayName": "Sergey Korpachev",
      "userId": "09181340988160569540"
     },
     "user_tz": -180
    },
    "id": "0c79232a",
    "outputId": "8c0b0ce2-b2af-4ce6-9408-140baad32372"
   },
   "outputs": [],
   "source": [
    "n_trees = [1, 5, 10, 100, 200, 300, 400, 500, 600, 700]\n",
    "quals_train = []\n",
    "quals_test = []\n",
    "for n in n_trees:\n",
    "    catboost = CatBoostClassifier(iterations=n, logging_level='Silent')\n",
    "    catboost.fit(X_train, y_train)\n",
    "    q_train = roc_auc_score(y_train, catboost.predict_proba(X_train)[:, 1])\n",
    "    q_test = roc_auc_score(y_test, catboost.predict_proba(X_test)[:, 1])\n",
    "    quals_train.append(q_train)\n",
    "    quals_test.append(q_test)\n",
    "\n",
    "plt.plot(n_trees, quals_train, marker='o', label='train')\n",
    "plt.plot(n_trees, quals_test, marker='o', label='test')\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('AUC-ROC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf36e153",
   "metadata": {
    "id": "cf36e153"
   },
   "source": [
    "## Xgboost\n",
    "\n",
    "1. Базовый алгоритм приближает направление, посчитанное с учетом второй производной функции потерь\n",
    "\n",
    "2. Функционал регуляризуется – добавляются штрафы за количество листьев и за норму коэффициентов\n",
    "\n",
    "3. При построении дерева используется критерий информативности, зависящий от оптимального вектора сдвига\n",
    "\n",
    "4. Критерий останова при обучении дерева также зависит от оптимального сдвига\n",
    "\n",
    "Ссылка на [источник](https://github.com/esokolov/ml-course-hse/blob/master/2021-fall/lecture-notes/lecture11-ensembles.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92bdf78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "executionInfo": {
     "elapsed": 2331,
     "status": "ok",
     "timestamp": 1700475875430,
     "user": {
      "displayName": "Sergey Korpachev",
      "userId": "09181340988160569540"
     },
     "user_tz": -180
    },
    "id": "e92bdf78",
    "outputId": "5e32b89d-90fa-4a54-ff06-6c743e1c219e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=300, verbosity=0)\n",
    "xgb.fit(X_train, y_train)\n",
    "plot_surface(X_test, y_test, xgb)\n",
    "\n",
    "print(roc_auc_score(y_test, xgb.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a290d2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "executionInfo": {
     "elapsed": 8869,
     "status": "ok",
     "timestamp": 1700475884293,
     "user": {
      "displayName": "Sergey Korpachev",
      "userId": "09181340988160569540"
     },
     "user_tz": -180
    },
    "id": "10a290d2",
    "outputId": "e343bde2-bb89-49a0-ade5-d1296acaf5c3"
   },
   "outputs": [],
   "source": [
    "n_trees = [1, 5, 10, 100, 200, 300, 400, 500, 600, 700]\n",
    "quals_train = []\n",
    "quals_test = []\n",
    "for n in n_trees:\n",
    "    xgboost = XGBClassifier(n_estimators=n, verbosity=0)\n",
    "    xgboost.fit(X_train, y_train)\n",
    "    q_train = roc_auc_score(y_train, xgboost.predict_proba(X_train)[:, 1])\n",
    "    q_test = roc_auc_score(y_test, xgboost.predict_proba(X_test)[:, 1])\n",
    "    quals_train.append(q_train)\n",
    "    quals_test.append(q_test)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(n_trees, quals_train, marker='.', label='train')\n",
    "plt.plot(n_trees, quals_test, marker='.', label='test')\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('AUC-ROC')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e14848b",
   "metadata": {
    "id": "3e14848b"
   },
   "source": [
    "Видно, что переобучились - качество на тесте только падает."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c973e678",
   "metadata": {
    "id": "c973e678"
   },
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c450d2c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 911,
     "status": "ok",
     "timestamp": 1700475885198,
     "user": {
      "displayName": "Sergey Korpachev",
      "userId": "09181340988160569540"
     },
     "user_tz": -180
    },
    "id": "c450d2c3",
    "outputId": "727d7982-bc68-4d9b-ccb5-ffc4109c1486"
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lightgbm = LGBMClassifier(n_estimators=300)\n",
    "lightgbm.fit(X_train, y_train)\n",
    "plot_surface(X_test, y_test, lightgbm)\n",
    "\n",
    "print(roc_auc_score(y_test, lightgbm.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5506bec3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4336,
     "status": "ok",
     "timestamp": 1700475889526,
     "user": {
      "displayName": "Sergey Korpachev",
      "userId": "09181340988160569540"
     },
     "user_tz": -180
    },
    "id": "5506bec3",
    "outputId": "af404326-01a9-4359-d6ee-04a0b8735003"
   },
   "outputs": [],
   "source": [
    "n_trees = [1, 5, 10, 100, 200, 300, 400, 500, 600, 700]\n",
    "quals_train = []\n",
    "quals_test = []\n",
    "for n in n_trees:\n",
    "    lightgbm = LGBMClassifier(n_estimators=n)\n",
    "    lightgbm.fit(X_train, y_train)\n",
    "    q_train = roc_auc_score(y_train, lightgbm.predict_proba(X_train)[:, 1])\n",
    "    q_test = roc_auc_score(y_test, lightgbm.predict_proba(X_test)[:, 1])\n",
    "    quals_train.append(q_train)\n",
    "    quals_test.append(q_test)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(n_trees, quals_train, marker='o', label='train')\n",
    "plt.plot(n_trees, quals_test, marker='o', label='test')\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('AUC-ROC')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0148c39f",
   "metadata": {
    "id": "0148c39f"
   },
   "source": [
    "В целом, у LightGBM получилась та же проблема с переобучением, как у Xgboost. Нужно дальше подбирать гиперпараметры для этих двух."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55aa170d",
   "metadata": {
    "id": "55aa170d"
   },
   "source": [
    "Попробуем взять фиксированное количество деревьев `n_estimators`, но будем менять их максимальную глубину `max_depth`. У этих алгоритмов разное время обучения, поэтому возьмем какой-то небольшой диапазон глубины и сравним все три модели - Catboost, LightGBM, Xgboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811fdb82",
   "metadata": {
    "id": "811fdb82"
   },
   "outputs": [],
   "source": [
    "def plot_model_diff_depths(model=LGBMClassifier, depth_range=list(range(1, 5)), n_trees=10):\n",
    "    roc_auc_train = []\n",
    "    roc_auc_test = []\n",
    "    for i in depth_range:\n",
    "        clf = model(n_estimators=n_trees, max_depth=i)\n",
    "        if type(clf) == type(CatBoostClassifier()):\n",
    "            clf = CatBoostClassifier(n_estimators=n_trees, max_depth=i, logging_level=\"Silent\")\n",
    "        clf.fit(X_train, y_train)\n",
    "        q_train = roc_auc_score(y_train, clf.predict_proba(X_train)[:, 1])\n",
    "        q_test = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "        roc_auc_train.append(q_train)\n",
    "        roc_auc_test.append(q_test)\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(depth_range, roc_auc_train, marker='o', label='train')\n",
    "    plt.plot(depth_range, roc_auc_test, marker='o', label='test')\n",
    "    plt.title(f'{model}')\n",
    "    plt.xlabel('Depth')\n",
    "    plt.ylabel('AUC-ROC')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b61d9d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 52214,
     "status": "ok",
     "timestamp": 1700475941728,
     "user": {
      "displayName": "Sergey Korpachev",
      "userId": "09181340988160569540"
     },
     "user_tz": -180
    },
    "id": "45b61d9d",
    "outputId": "ef8dbddd-a01a-4513-fdec-855520eaaa5f"
   },
   "outputs": [],
   "source": [
    "plot_model_diff_depths(model=LGBMClassifier, depth_range=list(range(1, 16, 2)), n_trees=100)\n",
    "plot_model_diff_depths(model=CatBoostClassifier, depth_range=list(range(1, 16, 2)), n_trees=100)\n",
    "plot_model_diff_depths(model=XGBClassifier, depth_range=list(range(1, 16, 2)), n_trees=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7272f497",
   "metadata": {
    "id": "7272f497"
   },
   "source": [
    "Когда мы обучили лучшие версии моделей, можно их сохранить и использовать для получения предсказаний, например, на новом батче данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5970a5",
   "metadata": {
    "id": "9b5970a5"
   },
   "outputs": [],
   "source": [
    "# Сохранить\n",
    "lightgbm.booster_.save_model('lightgbm.txt')\n",
    "catboost.save_model('catboost.cbm', format='cbm')\n",
    "xgboost.save_model('xgboost.json')\n",
    "\n",
    "# Загрузить\n",
    "lightgbm = LGBMClassifier(model_file='mode.txt')\n",
    "catboost = catboost.load_model('catboost.cbm')\n",
    "xgboost = xgboost.load_model('xgboost.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2c4337",
   "metadata": {
    "id": "4f2c4337"
   },
   "source": [
    "### Блендинг"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2094c5c9",
   "metadata": {
    "id": "2094c5c9"
   },
   "source": [
    "В этом подходе предсказания строятся как взвешенная сумма базовых алгоритмов.\n",
    "\n",
    "Рассмотрим простой пример блендинга градиентного бустинга и линейной регрессии для датасете `load_boston` и оценкой качества через RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b58dbb3",
   "metadata": {
    "id": "3b58dbb3"
   },
   "source": [
    "Поделим выборку на обучающую (60%), тестовую (20%) и валидационную (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tCuMnWKRE8VC",
   "metadata": {
    "id": "tCuMnWKRE8VC"
   },
   "outputs": [],
   "source": [
    "#from sklearn.datasets import load_boston\n",
    "# `load_boston` has been removed from scikit-learn since version 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HLFLsZ75E7jT",
   "metadata": {
    "id": "HLFLsZ75E7jT"
   },
   "outputs": [],
   "source": [
    "# !wget -i https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/datasets/data/boston_house_prices.csv\n",
    "#data_git = pd.read_csv('boston_house_prices.csv', sep=\"\\s+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yW5h3kELFPCR",
   "metadata": {
    "id": "yW5h3kELFPCR"
   },
   "source": [
    "**Data Set Characteristics:**  \n",
    "\n",
    "    :Number of Instances: 506\n",
    "\n",
    "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
    "\n",
    "    :Attribute Information (in order):\n",
    "        - CRIM     per capita crime rate by town\n",
    "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "        - INDUS    proportion of non-retail business acres per town\n",
    "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "        - NOX      nitric oxides concentration (parts per 10 million)\n",
    "        - RM       average number of rooms per dwelling\n",
    "        - AGE      proportion of owner-occupied units built prior to 1940\n",
    "        - DIS      weighted distances to five Boston employment centres\n",
    "        - RAD      index of accessibility to radial highways\n",
    "        - TAX      full-value property-tax rate per $10,000\n",
    "        - PTRATIO  pupil-teacher ratio by town\n",
    "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "        - LSTAT    % lower status of the population\n",
    "        - MEDV     Median value of owner-occupied homes in $1000's\n",
    "\n",
    "    :Missing Attribute Values: None\n",
    "\n",
    "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
    "\n",
    "This is a copy of UCI ML housing dataset.\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
    "\n",
    "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
    "\n",
    "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
    "prices and the demand for clean air', J. Environ. Economics & Management,\n",
    "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
    "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
    "pages 244-261 of the latter.\n",
    "\n",
    "The Boston house-price data has been used in many machine learning papers that address regression\n",
    "problems.   \n",
    "     \n",
    ".. topic:: References\n",
    "\n",
    "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
    "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AE5KGI2LFhc1",
   "metadata": {
    "id": "AE5KGI2LFhc1"
   },
   "outputs": [],
   "source": [
    "#data = load_boston()\n",
    "#X_init = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "#y_init = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nRFwGzz4FYzB",
   "metadata": {
    "id": "nRFwGzz4FYzB"
   },
   "outputs": [],
   "source": [
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PXSwcDL5FZaF",
   "metadata": {
    "id": "PXSwcDL5FZaF"
   },
   "outputs": [],
   "source": [
    "feature_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "\n",
    "X_init = pd.DataFrame(data, columns=feature_names, index=range(len(data)))\n",
    "#y_init = pd.DataFrame(target, columns=['MEDV'], index=range(len(target)))\n",
    "y_init = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ac4334",
   "metadata": {
    "id": "10ac4334"
   },
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(X_init, y_init, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "assert X_init.shape[0] == X_train.shape[0] + X_val.shape[0] + X_test.shape[0]\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    error = (y_true - y_pred) ** 2\n",
    "    return np.sqrt(np.mean(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a8f7c4",
   "metadata": {
    "id": "a9a8f7c4"
   },
   "source": [
    "Посмотрим, какое у нас качество у алгоритмов, если просто обучим на train и проверим качество на test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d20c745",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1700475942421,
     "user": {
      "displayName": "Sergey Korpachev",
      "userId": "09181340988160569540"
     },
     "user_tz": -180
    },
    "id": "1d20c745",
    "outputId": "a5df13a2-cd0b-4943-e1d7-7355e15072c6"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "cbm = CatBoostRegressor(iterations=100, max_depth=4, learning_rate=0.01, loss_function='RMSE', logging_level='Silent')\n",
    "cbm.fit(X_train, y_train)\n",
    "test_pred_cbm = cbm.predict(X_test)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "test_pred_lr = lr.predict(X_test)\n",
    "\n",
    "print(\"Test RMSE Linear Regression = %.3f\" % rmse(y_test, test_pred_lr))\n",
    "print(\"Test RMSE Catboost = %.3f\" % rmse(y_test, test_pred_cbm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1ce0cf",
   "metadata": {
    "id": "7f1ce0cf"
   },
   "source": [
    "Представим новый алгоритм $a(x)$ как взвешенную сумму из базовых алгоритмов:\n",
    "$$\n",
    "    a(x)\n",
    "    =\n",
    "    \\sum_{n = 1}^{N}\n",
    "    w_n b_n(x),\n",
    "$$\n",
    "где $\\sum_{n} w_n =1$ и нам нужно подобрать $w_n$.\n",
    "\n",
    "Сначала рассмотрим более простой случай, когда пробуем подбирать, с какими весами нам взять предсказания алгоритмов методом перебора пар весов (т.к. у нас только два алгоритма).\n",
    "\n",
    "Будем веса подбирать на валидации, а проверять качество на тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13c47e5",
   "metadata": {
    "id": "c13c47e5"
   },
   "outputs": [],
   "source": [
    "def select_weights(y_true, y_pred_1, y_pred_2):\n",
    "    grid = np.linspace(0, 1, 1000)\n",
    "    metric = []\n",
    "    for w_0 in grid:\n",
    "        w_1 = 1 - w_0\n",
    "        y_a = w_0 * y_pred_1 + w_1 * y_pred_2\n",
    "        metric.append([rmse(y_true, y_a), w_0, w_1])\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41aa170",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1700475942421,
     "user": {
      "displayName": "Sergey Korpachev",
      "userId": "09181340988160569540"
     },
     "user_tz": -180
    },
    "id": "d41aa170",
    "outputId": "e6777a42-14ce-4710-85c4-34e91f9350f8"
   },
   "outputs": [],
   "source": [
    "val_pred_cbm = cbm.predict(X_val)\n",
    "val_pred_lr = lr.predict(X_val)\n",
    "\n",
    "rmse_blending_train, w_0, w_1 = min(select_weights(y_val, val_pred_cbm, val_pred_lr), key=lambda x: x[0])\n",
    "rmse_blending_train, w_0, w_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28629f70",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1700475942421,
     "user": {
      "displayName": "Sergey Korpachev",
      "userId": "09181340988160569540"
     },
     "user_tz": -180
    },
    "id": "28629f70",
    "outputId": "4b391cdd-42c1-4db7-8e41-9f87e90cf569"
   },
   "outputs": [],
   "source": [
    "round(rmse(y_test, test_pred_cbm * w_0 + test_pred_lr * w_1), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624fbd0e",
   "metadata": {
    "id": "624fbd0e"
   },
   "source": [
    "В данном случае видно, что нам с помощью блендинга с весами примерно 26% из градиентного бустинга и 74% из линейной регрессии удалось снизить ошибку на тесте до 4.63."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13d5996",
   "metadata": {
    "id": "d13d5996"
   },
   "source": [
    "Давайте теперь напишем классическую версию блендинга, который выполняется по следующей схеме. Возьмем обучающую и тестовую выборку и разделим обучающую выборку на две части. На первой части обучим базовые алгоритмы, на второй - обучим мета-алгоритм из предсказаний базовых алгоритмов, и потом получим предсказания тестовых мета-признаках.\n",
    "<img src='https://alexanderdyakonov.files.wordpress.com/2017/03/stacking.png?w=1400' width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff547f31",
   "metadata": {
    "id": "ff547f31"
   },
   "source": [
    "Посмотрим на все шаги с самого начала, c момента загрузки исходных данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DRMJB7-JLeON",
   "metadata": {
    "id": "DRMJB7-JLeON"
   },
   "outputs": [],
   "source": [
    "#data = load_boston()\n",
    "#X_init = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "#y_init = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g9Dpju1kLgtc",
   "metadata": {
    "id": "g9Dpju1kLgtc"
   },
   "outputs": [],
   "source": [
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73RdFhBdLmEO",
   "metadata": {
    "id": "73RdFhBdLmEO"
   },
   "outputs": [],
   "source": [
    "feature_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "\n",
    "X_init = pd.DataFrame(data, columns=feature_names, index=range(len(data)))\n",
    "#y_init = pd.DataFrame(target, columns=['MEDV'], index=range(len(target)))\n",
    "y_init = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546b605d",
   "metadata": {
    "id": "546b605d"
   },
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(X_init, y_init, test_size=0.3, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "assert X_init.shape[0] == X_train.shape[0] + X_val.shape[0] + X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d423ad8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1700475943014,
     "user": {
      "displayName": "Sergey Korpachev",
      "userId": "09181340988160569540"
     },
     "user_tz": -180
    },
    "id": "5d423ad8",
    "outputId": "1f735ae0-fa7b-417a-b51b-dabce05b7eb8"
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "gb = CatBoostRegressor(iterations=100, max_depth=4, learning_rate=0.01, loss_function='RMSE', logging_level='Silent')\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "meta_train_df = pd.DataFrame()\n",
    "meta_train_df['gb_preds'] = gb.predict(X_val)\n",
    "meta_train_df['lr_preds'] = lr.predict(X_val)\n",
    "\n",
    "meta_algo = LGBMRegressor()\n",
    "meta_algo.fit(meta_train_df, y_val)\n",
    "\n",
    "meta_pred_df = pd.DataFrame()\n",
    "meta_pred_df['gb_preds'] = gb.predict(X_test)\n",
    "meta_pred_df['lr_preds'] = lr.predict(X_test)\n",
    "test_preds_meta = meta_algo.predict(meta_pred_df)\n",
    "\n",
    "rmse(y_test, test_preds_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c7583f",
   "metadata": {
    "id": "53c7583f"
   },
   "source": [
    "Получается, что при блендинге базовые алгоритмы и мета-алгоритм не используют весь объем выборки обучения, что является недостатком. Для повышения качества нужно усреднять несколько блендигов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9d526a",
   "metadata": {
    "id": "0d9d526a"
   },
   "source": [
    "### Стэкинг"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4491b6a7",
   "metadata": {
    "id": "4491b6a7"
   },
   "source": [
    "Попробуем реализовать стэкинг. Выборку разбивают на два фолда, последовательно перебирая фолды, обучают базовые алгоритмы на всех фолдах, кроме одного, а на оставшемся получают ответы базовых алгоритмов и используют их как значения соответствующих признаков на этом фолде. Для получения мета-признаков объектов тестовой выборки базовые алгоритмы обучают на всей обучающей выборке и берут их ответы на тестовой.\n",
    "\n",
    "<img src='https://alexanderdyakonov.files.wordpress.com/2017/03/stacking-2b.png?w=1400' width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea34549",
   "metadata": {
    "id": "fea34549"
   },
   "source": [
    "Для стэкинга можно пользоваться встроенной имплементацией в sklearn. Возьмем случайный лес и линейную регрессию как базовые алгоритмы, и потом обучим поверх с помощью 10-фолдовой кросс-валидации мета-алгоритм - градиентный бустинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27e4ef6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6355,
     "status": "ok",
     "timestamp": 1700475949368,
     "user": {
      "displayName": "Sergey Korpachev",
      "userId": "09181340988160569540"
     },
     "user_tz": -180
    },
    "id": "e27e4ef6",
    "outputId": "7fa15568-6de6-4082-f840-0ae6d65b7022"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor, RandomForestRegressor\n",
    "\n",
    "estimators = [('rf', RandomForestRegressor(n_estimators=200,random_state=42)),\n",
    "              ('lr', LinearRegression())]\n",
    "\n",
    "reg = StackingRegressor(estimators=estimators,\n",
    "                        cv=10,\n",
    "                        final_estimator=CatBoostRegressor(iterations=700, max_depth=5, learning_rate=0.01,\n",
    "                                       loss_function='RMSE', logging_level='Silent'))\n",
    "\n",
    "reg.fit(X_train, y_train).score(X_test, y_test)\n",
    "reg_preds = reg.predict(X_test)\n",
    "round(rmse(y_test, reg_preds), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6ab270",
   "metadata": {
    "id": "0b6ab270"
   },
   "source": [
    "Кстати, довольно полезно, что после обучения градиентного бустинга можно посмотреть на то, какие из признаков оказались наиболее важные и значимые (feature importances). Рассмотрим на примере Catboost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd952139",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1700475949368,
     "user": {
      "displayName": "Sergey Korpachev",
      "userId": "09181340988160569540"
     },
     "user_tz": -180
    },
    "id": "fd952139",
    "outputId": "0b085fb3-e762-4b50-d2b4-14dc3bf979cc"
   },
   "outputs": [],
   "source": [
    "gb = CatBoostRegressor(n_estimators=100, logging_level=\"Silent\")\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "for val, name in sorted(zip(gb.feature_importances_, feature_names))[::-1]:\n",
    "    print(name, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9a3603",
   "metadata": {
    "id": "ca9a3603"
   },
   "source": [
    "Важность признака &mdash; это то, насколько в среднем меняется ответ модели при изменении значения данного признака (изменении значения разбиения).\n",
    "\n",
    "$$feature\\_importance_{F} = \\sum_{tree, leaves_F} (v_1 - avr)^2\\cdot c_1 +(v_2 - avr)^2\\cdot c_2\\\\\n",
    "\\qquad avr = \\frac{v_1 \\cdot c_1 + v_2 \\cdot c_2}{c_1 + c_2}.$$\n",
    "\n",
    "Запись $leaves_F$ означает разбиение, зависящее от признака $F$.\n",
    "\n",
    "Мы сравниваем поддеревья, отличающиеся значением сплита в узле на пути к ним: если условие сплита выполняется, объект попадает в левое поддерево, иначе &mdash; в правое. $c_1, c_2 - $  число объектов обучающего датасета, попавших в левое и правое поддерево соотвественно, либо суммарный вес этих объектов, если используются веса; $v1, v2 -$значение модели в левом и правом поддереве.\n",
    "Значения $feature\\_importance$ нормируются и суммируются в 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c602f84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 552
    },
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1700475949781,
     "user": {
      "displayName": "Sergey Korpachev",
      "userId": "09181340988160569540"
     },
     "user_tz": -180
    },
    "id": "5c602f84",
    "outputId": "e88e1f1c-2919-42a8-e078-7addd314b83f"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(dict(zip(feature_names, gb.feature_importances_)),\n",
    "                       orient='index').reset_index()\n",
    "df.columns = ['features', 'score']\n",
    "df.sort_values(by='score', ascending=False, inplace=True)\n",
    "df.plot(x='features', y='score', kind='bar', title='Feature importances')\n",
    "plt.ylabel('Score');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2482bbc",
   "metadata": {
    "id": "b2482bbc"
   },
   "source": [
    "Так же, для измерения важности признаков используются вектора Шепли. Имплементация доступна в [библиотеке SHAP](https://github.com/slundberg/shap). Будем зашумлять входные данные по каждой переменной, чтобы понять, важная она или нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f962e7af",
   "metadata": {
    "id": "f962e7af",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip3 install shap==0.31.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xb_4b1-zNtc5",
   "metadata": {
    "id": "Xb_4b1-zNtc5"
   },
   "outputs": [],
   "source": [
    "#!pip3 install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f279c1d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "executionInfo": {
     "elapsed": 5482,
     "status": "ok",
     "timestamp": 1700475955259,
     "user": {
      "displayName": "Sergey Korpachev",
      "userId": "09181340988160569540"
     },
     "user_tz": -180
    },
    "id": "f279c1d3",
    "outputId": "0e9b2eac-a986-45b6-bd26-27e9b5085a2f"
   },
   "outputs": [],
   "source": [
    "from catboost import Pool\n",
    "import shap\n",
    "\n",
    "shap_values = gb.get_feature_importance(Pool(X), type='ShapValues')\n",
    "\n",
    "expected_value = shap_values[0,-1]\n",
    "shap_values = shap_values[:,:-1]\n",
    "\n",
    "shap.summary_plot(shap_values, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cf9297",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1700475955259,
     "user": {
      "displayName": "Sergey Korpachev",
      "userId": "09181340988160569540"
     },
     "user_tz": -180
    },
    "id": "50cf9297",
    "outputId": "d9890969-1042-4f28-9f54-053d067ecffc"
   },
   "outputs": [],
   "source": [
    "print(f'Диапазон значений целевой переменной ({y.min()}, {y.max()})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0465a4",
   "metadata": {
    "id": "4a0465a4"
   },
   "source": [
    "Как его читать:\n",
    "\n",
    "- Значения по оси X - отрицательное или положительное влияние на целевую переменную при изменении признаков.\n",
    "- Чем краснее точки на графике, тем выше значения фичи в ней\n",
    "- Чем толще линия на графике, тем больше таких точек наблюдения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52160f85",
   "metadata": {
    "id": "52160f85"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
